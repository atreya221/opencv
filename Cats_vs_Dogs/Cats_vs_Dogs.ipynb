{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cats_vs_Dogs.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZjm_68FiAsw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zA0b7h8qDXPB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Mounted google drive at session storage\n",
        "\n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive/', force_remount = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2HylT4qXNEY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pathlib\n",
        "import zipfile\n",
        "\n",
        "#Modify next line according to your drive location or local os path\n",
        "\n",
        "zip_ref = zipfile.ZipFile(\"/content/drive/My Drive/Classroom/Artificial Intelligence-07B1/Cats vs Dogs Image Classification/train_ds.zip\", 'r')\n",
        "zip_ref.extractall(\"/content/data/train\")  # extracted data from zip file 'train_ds.zip'\n",
        "\n",
        "data_dir = pathlib.Path(\"/content/data/train/train\")  # store path of train dataset\n",
        "zip_ref.close()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGunYKRVvwIc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5d6ac258-c0bf-4b5d-d343-f6cf8efeee4b"
      },
      "source": [
        "data_dir"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PosixPath('/content/data/train/train')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gk7POKd4YYGl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "dcb36c62-38bd-44da-aa5a-d2c50a5c7db9"
      },
      "source": [
        "# total image count\n",
        "\n",
        "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
        "print(image_count)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBVY6wMHa6WQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "32415340-51cd-4f9a-f876-df3f5d47c942"
      },
      "source": [
        "batch_size = 32\n",
        "\n",
        "# resize all images to size (180,180)\n",
        "img_height = 180\n",
        "img_width = 180\n",
        "\n",
        "# Create training set from images directory using keras.preprocessing\n",
        "\n",
        "train_ds = keras.preprocessing.image_dataset_from_directory(\n",
        "    data_dir,\n",
        "    validation_split = 0.2,\n",
        "    subset = \"training\",\n",
        "    seed = 123,\n",
        "    image_size = (img_height, img_width),\n",
        "    batch_size = batch_size\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 25000 files belonging to 2 classes.\n",
            "Using 20000 files for training.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ds8SygN8bNSo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "d79fccd6-b4dd-466d-abd6-79c17f67663f"
      },
      "source": [
        "# Create validation set from images directory (train - 0.8, validation - 0.2)\n",
        "\n",
        "val_ds = keras.preprocessing.image_dataset_from_directory(\n",
        "    data_dir,\n",
        "    validation_split = 0.2,\n",
        "    subset = \"validation\",\n",
        "    seed = 123,\n",
        "    image_size = (img_height, img_width),\n",
        "    batch_size = batch_size\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 25000 files belonging to 2 classes.\n",
            "Using 5000 files for validation.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RI1kh_F9bVyW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "72195b34-754b-4a68-bba7-44f79562aad3"
      },
      "source": [
        "classes = train_ds.class_names\n",
        "print(classes)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['cat', 'dog']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmQ8ZY4Pbg7j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "53ea83ad-d53b-4f05-af90-94bb4e168aa5"
      },
      "source": [
        "for images, labels in train_ds:\n",
        "  images_shape = images.shape\n",
        "  labels_shape = labels.shape\n",
        "  print(images.shape)\n",
        "  print(labels.shape)\n",
        "  print(type(images))\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(32, 180, 180, 3)\n",
            "(32,)\n",
            "<class 'tensorflow.python.framework.ops.EagerTensor'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6opbvBOTwA1w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "d5556d53-8247-4c5f-d21b-db4a11a2ffc5"
      },
      "source": [
        "for images, labels in val_ds:\n",
        "  print(images.shape)\n",
        "  print(labels.shape)\n",
        "  break\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(32, 180, 180, 3)\n",
            "(32,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCC_ItqnzOpq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import Sequential\n",
        "# from keras.preprocessing.image import ImageDataGenerator\n",
        "# try to use ImageDataGenerator (Data augmentation e.g random flips, crops..) to improve accuracy\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWZ97ys459-H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define the model architecture\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(keras.layers.experimental.preprocessing.Rescaling(1./255, input_shape=(180, 180, 3))) # Normalize the dataset to improve accuracy\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), activation='relu'))  \n",
        "model.add(BatchNormalization())  # normalize the activations after each layer\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))  # random dropping of units to prevent overfitting and improve validation accuracy\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='sigmoid'))  # sigmoid activation used as only 2 classes are present"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2jeJs4S7a_X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 812
        },
        "outputId": "479c122f-f657-45b6-8d51-b8519f721e81"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "rescaling_5 (Rescaling)      (None, 180, 180, 3)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 178, 178, 32)      896       \n",
            "_________________________________________________________________\n",
            "batch_normalization_16 (Batc (None, 178, 178, 32)      128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_12 (MaxPooling (None, 89, 89, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_16 (Dropout)         (None, 89, 89, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 87, 87, 64)        18496     \n",
            "_________________________________________________________________\n",
            "batch_normalization_17 (Batc (None, 87, 87, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_13 (MaxPooling (None, 43, 43, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_17 (Dropout)         (None, 43, 43, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 41, 41, 128)       73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_18 (Batc (None, 41, 41, 128)       512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_14 (MaxPooling (None, 20, 20, 128)       0         \n",
            "_________________________________________________________________\n",
            "dropout_18 (Dropout)         (None, 20, 20, 128)       0         \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 51200)             0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 512)               26214912  \n",
            "_________________________________________________________________\n",
            "batch_normalization_19 (Batc (None, 512)               2048      \n",
            "_________________________________________________________________\n",
            "dropout_19 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 1)                 513       \n",
            "=================================================================\n",
            "Total params: 26,311,617\n",
            "Trainable params: 26,310,145\n",
            "Non-trainable params: 1,472\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59kPdMAWhIOR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss = keras.losses.BinaryCrossentropy(), optimizer = 'adam', metrics = ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHcUThXAIQsO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# callbacks used to prevent model from diverging and reduce learning rate (by factor of 0.5) as we approach minima\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "earlystop = EarlyStopping(patience=10)\n",
        "\n",
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', \n",
        "                                            patience=2, \n",
        "                                            verbose=1, \n",
        "                                            factor=0.5, \n",
        "                                            min_lr=0.00001)\n",
        "\n",
        "callbacks = [earlystop, learning_rate_reduction]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Jm9r6kxhnBQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 796
        },
        "outputId": "c32a59f6-65af-498a-a167-571ea69e5a7d"
      },
      "source": [
        "# Early stoppage as validation loss has become saturated\n",
        "history = model.fit(train_ds, validation_data = val_ds, validation_steps = 157, steps_per_epoch = 625, epochs = 20, callbacks = callbacks)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "625/625 [==============================] - 71s 113ms/step - loss: 0.6703 - accuracy: 0.6688 - val_loss: 0.5757 - val_accuracy: 0.6992\n",
            "Epoch 2/20\n",
            "625/625 [==============================] - 70s 113ms/step - loss: 0.4874 - accuracy: 0.7645 - val_loss: 0.5454 - val_accuracy: 0.7370\n",
            "Epoch 3/20\n",
            "625/625 [==============================] - 71s 114ms/step - loss: 0.4514 - accuracy: 0.7864 - val_loss: 0.4466 - val_accuracy: 0.7904\n",
            "Epoch 4/20\n",
            "625/625 [==============================] - 71s 113ms/step - loss: 0.3765 - accuracy: 0.8317 - val_loss: 0.4643 - val_accuracy: 0.7774\n",
            "Epoch 5/20\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.3209 - accuracy: 0.8605\n",
            "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "625/625 [==============================] - 71s 113ms/step - loss: 0.3209 - accuracy: 0.8605 - val_loss: 0.8630 - val_accuracy: 0.6998\n",
            "Epoch 6/20\n",
            "625/625 [==============================] - 71s 113ms/step - loss: 0.2306 - accuracy: 0.9064 - val_loss: 0.4209 - val_accuracy: 0.8276\n",
            "Epoch 7/20\n",
            "625/625 [==============================] - 71s 113ms/step - loss: 0.1793 - accuracy: 0.9302 - val_loss: 0.3632 - val_accuracy: 0.8538\n",
            "Epoch 8/20\n",
            "625/625 [==============================] - 71s 113ms/step - loss: 0.1615 - accuracy: 0.9366 - val_loss: 1.5739 - val_accuracy: 0.6480\n",
            "Epoch 9/20\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.1246 - accuracy: 0.9524\n",
            "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "625/625 [==============================] - 71s 113ms/step - loss: 0.1246 - accuracy: 0.9524 - val_loss: 0.5446 - val_accuracy: 0.8260\n",
            "Epoch 10/20\n",
            "625/625 [==============================] - 71s 113ms/step - loss: 0.0860 - accuracy: 0.9693 - val_loss: 0.4006 - val_accuracy: 0.8656\n",
            "Epoch 11/20\n",
            "625/625 [==============================] - 71s 114ms/step - loss: 0.0647 - accuracy: 0.9780 - val_loss: 0.4182 - val_accuracy: 0.8558\n",
            "Epoch 12/20\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.0506 - accuracy: 0.9834\n",
            "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "625/625 [==============================] - 71s 113ms/step - loss: 0.0506 - accuracy: 0.9834 - val_loss: 0.5928 - val_accuracy: 0.8360\n",
            "Epoch 13/20\n",
            "625/625 [==============================] - 71s 113ms/step - loss: 0.0470 - accuracy: 0.9842 - val_loss: 0.4541 - val_accuracy: 0.8616\n",
            "Epoch 14/20\n",
            "625/625 [==============================] - 71s 113ms/step - loss: 0.0352 - accuracy: 0.9889 - val_loss: 0.4504 - val_accuracy: 0.8676\n",
            "Epoch 15/20\n",
            "625/625 [==============================] - 71s 113ms/step - loss: 0.0377 - accuracy: 0.9872 - val_loss: 0.4914 - val_accuracy: 0.8620\n",
            "Epoch 16/20\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.0276 - accuracy: 0.9913\n",
            "Epoch 00016: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "625/625 [==============================] - 71s 113ms/step - loss: 0.0276 - accuracy: 0.9913 - val_loss: 0.4760 - val_accuracy: 0.8648\n",
            "Epoch 17/20\n",
            "625/625 [==============================] - 71s 113ms/step - loss: 0.0262 - accuracy: 0.9917 - val_loss: 0.4574 - val_accuracy: 0.8666\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aw6NPesgh1Bd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "aaf5d668-9ab7-4dab-9d6f-a4e70a3133b4"
      },
      "source": [
        "#serialize model to JSON\n",
        "model_json = model.to_json()\n",
        "with open(\"model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "# serialize weights to HDF5\n",
        "model.save_weights(\"model.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9CDyX5-PBbM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The model saved here can be used in the actual .py file to test images\n",
        "# This model should only be used to train the model.\n",
        "\n",
        "# References\n",
        "# https://www.kaggle.com/uysimty/keras-cnn-dog-or-cat-classification"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}